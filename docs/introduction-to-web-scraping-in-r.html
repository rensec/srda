<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Introduction to web scraping in R | Social Research in the Digital Age (Utrecht University)</title>
  <meta name="description" content="2 Introduction to web scraping in R | Social Research in the Digital Age (Utrecht University)" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Introduction to web scraping in R | Social Research in the Digital Age (Utrecht University)" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Introduction to web scraping in R | Social Research in the Digital Age (Utrecht University)" />
  
  
  

<meta name="author" content="Rense Corten" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="a-very-short-introduction-to-r.html"/>
<link rel="next" href="collecting-data-through-apis-the-case-of-reddit.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#usage"><i class="fa fa-check"></i>Usage</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html"><i class="fa fa-check"></i><b>1</b> A Very Short Introduction to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#what-is-r-and-why-should-you-learn-it"><i class="fa fa-check"></i><b>1.1.1</b> What is R and why should you learn it?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#using-rstudio"><i class="fa fa-check"></i><b>1.2</b> Using RStudio</a></li>
<li class="chapter" data-level="1.3" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#running-code-from-the-r-script"><i class="fa fa-check"></i><b>1.3</b> Running code from the R script</a></li>
<li class="chapter" data-level="1.4" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#using-objects-assigning-values-to-names"><i class="fa fa-check"></i><b>1.4</b> Using objects: Assigning values to names</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#practice-problem-1"><i class="fa fa-check"></i><b>1.4.1</b> PRACTICE PROBLEM 1</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#comments"><i class="fa fa-check"></i><b>1.5</b> Comments</a></li>
<li class="chapter" data-level="1.6" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#installing-packages"><i class="fa fa-check"></i><b>1.6</b> Installing Packages</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#practice-problem-2"><i class="fa fa-check"></i><b>1.6.1</b> PRACTICE PROBLEM 2</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#the-working-directory"><i class="fa fa-check"></i><b>1.7</b> The working directory</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#practice-problem-3"><i class="fa fa-check"></i><b>1.7.1</b> PRACTICE PROBLEM 3</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#interacting-with-the-environment"><i class="fa fa-check"></i><b>1.8</b> Interacting with the Environment</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#practice-problem-4"><i class="fa fa-check"></i><b>1.8.1</b> PRACTICE PROBLEM 4</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#back-to-writing-code"><i class="fa fa-check"></i><b>1.9</b> Back to writing code</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#mathematical-operators"><i class="fa fa-check"></i><b>1.9.1</b> Mathematical Operators</a></li>
<li class="chapter" data-level="1.9.2" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#logical-comparisons"><i class="fa fa-check"></i><b>1.9.2</b> Logical Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#data-structures"><i class="fa fa-check"></i><b>1.10</b> Data structures</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#vectors"><i class="fa fa-check"></i><b>1.10.1</b> Vectors</a></li>
<li class="chapter" data-level="1.10.2" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#data-frames"><i class="fa fa-check"></i><b>1.10.2</b> Data frames</a></li>
<li class="chapter" data-level="1.10.3" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#selecting-rows-columns-and-elements-in-data-frames"><i class="fa fa-check"></i><b>1.10.3</b> Selecting rows, columns and elements in data frames</a></li>
<li class="chapter" data-level="1.10.4" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#practice-problem-7"><i class="fa fa-check"></i><b>1.10.4</b> PRACTICE PROBLEM 7</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#getting-data-into-r"><i class="fa fa-check"></i><b>1.11</b> Getting data into R</a>
<ul>
<li class="chapter" data-level="1.11.1" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#summarising-the-data"><i class="fa fa-check"></i><b>1.11.1</b> Summarising the data</a></li>
</ul></li>
<li class="chapter" data-level="1.12" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#saving-data"><i class="fa fa-check"></i><b>1.12</b> Saving data</a></li>
<li class="chapter" data-level="1.13" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#functions"><i class="fa fa-check"></i><b>1.13</b> Functions</a>
<ul>
<li class="chapter" data-level="1.13.1" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#using-functions"><i class="fa fa-check"></i><b>1.13.1</b> Using functions</a></li>
<li class="chapter" data-level="1.13.2" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#practice-problem-8"><i class="fa fa-check"></i><b>1.13.2</b> PRACTICE PROBLEM 8</a></li>
</ul></li>
<li class="chapter" data-level="1.14" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#getting-help-viewing-and-interpreting-function-documentation"><i class="fa fa-check"></i><b>1.14</b> Getting help: viewing and interpreting function documentation</a>
<ul>
<li class="chapter" data-level="1.14.1" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html#practice-problem-9"><i class="fa fa-check"></i><b>1.14.1</b> PRACTICE PROBLEM 9</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html"><i class="fa fa-check"></i><b>2</b> Introduction to web scraping in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#some-preliminaries-about-websites-scraping-and-crawling"><i class="fa fa-check"></i><b>2.1</b> Some preliminaries: about websites, scraping, and crawling</a></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#getting-our-tools-ready"><i class="fa fa-check"></i><b>2.2</b> Getting our tools ready</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#getting-to-know-the-target-website"><i class="fa fa-check"></i><b>2.3</b> Getting to know the target website</a></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#making-a-plan"><i class="fa fa-check"></i><b>2.4</b> Making a plan</a></li>
<li class="chapter" data-level="2.5" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#locating-the-correct-information"><i class="fa fa-check"></i><b>2.5</b> Locating the correct information</a></li>
<li class="chapter" data-level="2.6" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#building-the-scraper"><i class="fa fa-check"></i><b>2.6</b> Building the scraper</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#first-steps"><i class="fa fa-check"></i><b>2.6.1</b> First steps</a></li>
<li class="chapter" data-level="2.6.2" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#automating-the-process-getting-multiple-pages"><i class="fa fa-check"></i><b>2.6.2</b> Automating the process: getting multiple pages</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#answering-the-research-question"><i class="fa fa-check"></i><b>2.7</b> Answering the research question</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#collecting-the-data"><i class="fa fa-check"></i><b>2.7.1</b> Collecting the data</a></li>
<li class="chapter" data-level="2.7.2" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#analyzing-the-data"><i class="fa fa-check"></i><b>2.7.2</b> Analyzing the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="collecting-data-through-apis-the-case-of-reddit.html"><a href="collecting-data-through-apis-the-case-of-reddit.html"><i class="fa fa-check"></i><b>3</b> Collecting data through APIs: the case of Reddit</a>
<ul>
<li class="chapter" data-level="3.1" data-path="collecting-data-through-apis-the-case-of-reddit.html"><a href="collecting-data-through-apis-the-case-of-reddit.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="collecting-data-through-apis-the-case-of-reddit.html"><a href="collecting-data-through-apis-the-case-of-reddit.html#loading-the-tools"><i class="fa fa-check"></i><b>3.2</b> Loading the tools</a></li>
<li class="chapter" data-level="3.3" data-path="collecting-data-through-apis-the-case-of-reddit.html"><a href="collecting-data-through-apis-the-case-of-reddit.html#case-study-reddit"><i class="fa fa-check"></i><b>3.3</b> Case study: Reddit</a></li>
<li class="chapter" data-level="3.4" data-path="collecting-data-through-apis-the-case-of-reddit.html"><a href="collecting-data-through-apis-the-case-of-reddit.html#accessing-data-via-the-api"><i class="fa fa-check"></i><b>3.4</b> Accessing data via the API</a></li>
<li class="chapter" data-level="3.5" data-path="collecting-data-through-apis-the-case-of-reddit.html"><a href="collecting-data-through-apis-the-case-of-reddit.html#getting-the-data-with-redditextractor"><i class="fa fa-check"></i><b>3.5</b> Getting the data with RedditExtractoR</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="collecting-data-through-apis-the-case-of-reddit.html"><a href="collecting-data-through-apis-the-case-of-reddit.html#getting-threads"><i class="fa fa-check"></i><b>3.5.1</b> Getting threads</a></li>
<li class="chapter" data-level="3.5.2" data-path="collecting-data-through-apis-the-case-of-reddit.html"><a href="collecting-data-through-apis-the-case-of-reddit.html#getting-contents-of-threads"><i class="fa fa-check"></i><b>3.5.2</b> Getting contents of threads</a></li>
<li class="chapter" data-level="3.5.3" data-path="collecting-data-through-apis-the-case-of-reddit.html"><a href="collecting-data-through-apis-the-case-of-reddit.html#creating-a-network"><i class="fa fa-check"></i><b>3.5.3</b> Creating a network</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Social Research in the Digital Age (Utrecht University)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-to-web-scraping-in-r" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">2</span> Introduction to web scraping in R<a href="introduction-to-web-scraping-in-r.html#introduction-to-web-scraping-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This is a tutorial to illustrate the use or R for scraping in a social science context. The application is the Dutch website www.petities.nl, which is a platform where anyone can start a petition for any cause and collect signatures. Such websites fit into a larger trend in which citizens increasingly use the power of the internet to challenge the political status quo. The petitions listed here address a large variety of issues, some more serious than others. Interestingly, some petitions become very successful, while other peter out quickly. What drives such processes? To start addressing this question, we collect some data from this website using a scraper that we build in R. As a motivating research question, let’s state the following simple descriptive question: <em>what does the variation in success between petitions look like</em>? For a first hypothesis on what this might look like, have a look at Fig. 3.4 in the chapter by Margetts et al., as discussed in the seminar.</p>
<div id="some-preliminaries-about-websites-scraping-and-crawling" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Some preliminaries: about websites, scraping, and crawling<a href="introduction-to-web-scraping-in-r.html#some-preliminaries-about-websites-scraping-and-crawling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To get started, we need to understand a bit about the technical nature of web scraping. What is web scraping? For our context, which is social science-oriented research, we typically refer to web scraping as the automated collection of information from websites. In principle, there is nothing fancy about collecting or downloading information from websites. In fact, when you view a website, your browser does exactly this: it downloads some file from a server (such as an html-file) and renders it in a way that looks pretty. If you go to www.petities.nl, you can view this file by right-clicking on the page and selecting “view page source” (in various browsers this may be called slightly differently), which will, in this case, show the the HTML-code which produces the page. The information we want to collect for our research is somehow embedded in this code, and to view it we are already downloading it, so downloading the information <em>per se</em> is not so much the challenge. The real challenges in a web scraping project are a little bit more specific, namely:</p>
<ol style="list-style-type: decimal">
<li><p>We want to download a large amount of information in a <em>systematic</em> and <em>automated</em> way;</p></li>
<li><p>We want to <em>process</em> the information in a way such that we can easily analyze the data later.</p></li>
</ol>
<p>Step 1 above typically involves that we want to automatically visit a number of web pages, in a systematic way, even if we don’t know all the URL’s of these pages beforehand. For example, on a social media website, we may want to get a list of a given user’s followers, and once we have these followers, <em>their</em> followers, etc. This process of discovering websites by following links is called <em>crawling</em>. Web <em>scraping,</em> in the strict sense of the word, refers to the downloading (and processing) of the information found on those websites. A typical data collection task, then, does both: crawling the web to find relevant websites in a specified way, and in the process storing information from these websites. Generally, when we speak about “web scraping” or “a web scraper”, we actually mean a process or a piece of software that does both crawl and scrape. So let’s build a web scraper for petities.nl.</p>
</div>
<div id="getting-our-tools-ready" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Getting our tools ready<a href="introduction-to-web-scraping-in-r.html#getting-our-tools-ready" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>First, we need to collect some tools, starting with some R packages. Start a new R script, copy and paste the following code, and run it:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="introduction-to-web-scraping-in-r.html#cb54-1" tabindex="-1"></a><span class="fu">install.packages</span>(</span>
<span id="cb54-2"><a href="introduction-to-web-scraping-in-r.html#cb54-2" tabindex="-1"></a>  <span class="fu">c</span>(</span>
<span id="cb54-3"><a href="introduction-to-web-scraping-in-r.html#cb54-3" tabindex="-1"></a>    <span class="st">&quot;rvest&quot;</span>, <span class="co"># the main package for scraping</span></span>
<span id="cb54-4"><a href="introduction-to-web-scraping-in-r.html#cb54-4" tabindex="-1"></a>    <span class="st">&quot;stringr&quot;</span>, <span class="co"># some useful functions for working with strings</span></span>
<span id="cb54-5"><a href="introduction-to-web-scraping-in-r.html#cb54-5" tabindex="-1"></a>    <span class="st">&quot;tidyverse&quot;</span>), <span class="co"># for general data handling</span></span>
<span id="cb54-6"><a href="introduction-to-web-scraping-in-r.html#cb54-6" tabindex="-1"></a>  <span class="at">repos =</span> <span class="st">&quot;http://cran.us.r-project.org&quot;</span></span>
<span id="cb54-7"><a href="introduction-to-web-scraping-in-r.html#cb54-7" tabindex="-1"></a>)</span></code></pre></div>
<p>We then activate these packages for this session with library commands:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="introduction-to-web-scraping-in-r.html#cb55-1" tabindex="-1"></a><span class="fu">library</span>(rvest)  <span class="co">#scraping</span></span>
<span id="cb55-2"><a href="introduction-to-web-scraping-in-r.html#cb55-2" tabindex="-1"></a><span class="fu">library</span>(stringr) <span class="co"># string functions</span></span>
<span id="cb55-3"><a href="introduction-to-web-scraping-in-r.html#cb55-3" tabindex="-1"></a><span class="fu">library</span>(tidyverse) <span class="co"># for general data handling</span></span></code></pre></div>
<p>Second, we need to add some special tool to our browser to get a better understanding of -and grip on- the website that we are scraping. I use Firefox, for which the <a href="https://addons.mozilla.org/en-US/firefox/addon/scrapemate/">add-on “ScrapeMate”</a> is available. Chrome has different extensions for the same purpose, and so may other extendable browsers. Note that results may differ between browsers and extensions from website to website, so if you can’t figure out a website (you’ll see what I mean by that later) using one particular browser-extension combination, it’s always worth trying other combinations. Go go ahead and install the relevant extension for your browser.</p>
</div>
<div id="getting-to-know-the-target-website" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Getting to know the target website<a href="introduction-to-web-scraping-in-r.html#getting-to-know-the-target-website" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Before we start coding, it’s always a good idea to get a little bit acquainted with the website we’re scraping. Go to Petities.nl and try to anwer the following <strong>questions</strong>:</p>
<ul>
<li><p>Which information is shown about each petition?</p></li>
<li><p>How are petitions sorted?</p></li>
<li><p>What different options do we have to show and sort petitions? Which one do you think is most useful for our purpose?</p></li>
<li><p>What do the numbers in the bottom left and -right of each “petition box” mean?</p></li>
<li><p>What is your impression about the sort of petitions that are posted here? Does anything stand out?</p></li>
</ul>
<p>Also, once more look at the page source code (see above). Which part of the content of the page can you already identify in the source code (and which not)? You’ll notice that there is a lot of code that does not seem to refer to any content; things like <code>class="search-container whitespace".</code> This is called <em>CSS</em> (for <em>Cascading Style Sheets</em>) and it determines what a website looks like, by applying certain formatting rules to things that should look familiar (not unlike, for example, the style templates of Microsoft Word or Powerpoint). We’ll take advantage of this later to locate information on the page.</p>
</div>
<div id="making-a-plan" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Making a plan<a href="introduction-to-web-scraping-in-r.html#making-a-plan" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Also, before starting to build our scraper (or before any data collection project, really) it is helpful to already have an idea of what we want our final data set to look like. For now, let’s start simple, and aim for a data set that is basically a list of petitions, and which contains for every petition:</p>
<ol style="list-style-type: decimal">
<li><p>The title of the petition</p></li>
<li><p>The url of the petition page</p></li>
<li><p>The number of signatures</p></li>
</ol>
<p>As a data frame, the data should eventually look something like this:</p>
<table>
<caption>What the target data set should look like</caption>
<colgroup>
<col width="16%" />
<col width="66%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>link_url</th>
<th>Sig_Count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>“my petition”</td>
<td>“<a href="https://petities.nl/petitions" class="uri">https://petities.nl/petitions</a><a href="https://petities.nl/petitions/my">/my</a>_petition”</td>
<td>9</td>
</tr>
<tr class="even">
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
<tr class="odd">
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
<tr class="even">
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<p>Check and see whether you can visually identify this information on the website.</p>
</div>
<div id="locating-the-correct-information" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Locating the correct information<a href="introduction-to-web-scraping-in-r.html#locating-the-correct-information" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As a starting piont, let’s take the section of the website that lists all petitions: <a href="https://petities.nl/petitions/all?locale=en" class="uri">https://petities.nl/petitions/all?locale=en</a>. When we look at the source code of the page, we can actually already identify all the information that we need in the code. This, however, is rather messy, and not something we can analyze directly. We somehow need to get the information in the shape of our data table above, and for this we first need to automatically extract the titles, URLs, and counts from the messy source code.</p>
<p>This is where our browser extension comes in handy. When we look at the website (not the code), we can actually easily identify the relevant information <em>because it is formatted in a consistent way</em>. To achieve this, the website uses CSS tags in the code, and we can take advantage of that to find the relevant information. We could already do that by looking hard at the code, but our browser extension make it easier. Let’s start with the titles.</p>
<p>In Firefox:</p>
<ol style="list-style-type: decimal">
<li>Go to <a href="https://petities.nl/petitions/all?locale=en" class="uri">https://petities.nl/petitions/all?locale=en</a></li>
<li>Click the icon for the “Scrapemate” extension in the toolbar (the little wand)</li>
<li>In the resulting sidebar on the right, click the top orange button (“start picker”)</li>
<li>Click the title of a petition. A few things will happen:
<ol style="list-style-type: decimal">
<li>All the titles of the petitions shown on the page will be highlighted. This is an indication that you’ve identified the right “field”; we want all those titles!</li>
<li>In the bottom right, you will see a list of all the titles. Again, this is what we want!</li>
<li>In the bar below the orange button, you’ll see “<code>.petition-overview-info-title</code>”. This is the relevant CSS tag: basically it tells the browser “show this piece of text as a petition title” (and the actual style of a petition title is stored somewhere in a CSS style file, but we don’t care about that).</li>
</ol></li>
</ol>
<p>In building our scraper, we can now make use of that: we can basically tell it to “collect all the pieces of text that are formatted like petition titles”, and we now also know that these pieces of text are marked in the source code as “<code>.petition-overview-info-title</code>” (you can actually see this tag in the source code). So let’s get coding!</p>
</div>
<div id="building-the-scraper" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> Building the scraper<a href="introduction-to-web-scraping-in-r.html#building-the-scraper" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="first-steps" class="section level3 hasAnchor" number="2.6.1">
<h3><span class="header-section-number">2.6.1</span> First steps<a href="introduction-to-web-scraping-in-r.html#first-steps" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We now turn to the <code>rvest</code> package. To begin, we simply download the entire page:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="introduction-to-web-scraping-in-r.html#cb56-1" tabindex="-1"></a><span class="co"># Simple version without polite and without pipes</span></span>
<span id="cb56-2"><a href="introduction-to-web-scraping-in-r.html#cb56-2" tabindex="-1"></a>webpage <span class="ot">&lt;-</span> <span class="fu">read_html</span>(<span class="st">&quot;https://petities.nl/petitions/all?locale=en&quot;</span>) </span>
<span id="cb56-3"><a href="introduction-to-web-scraping-in-r.html#cb56-3" tabindex="-1"></a>webpage</span></code></pre></div>
<p>This basically just behaves like a browser: it downloads the source code of the page. It still looks like unintelligible code soup.</p>
<p>However, we now know what to look for in this soup. Using the <code>html_nodes()</code> function from <code>rvest</code>, we can identify all the titles:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="introduction-to-web-scraping-in-r.html#cb57-1" tabindex="-1"></a>title <span class="ot">&lt;-</span> <span class="fu">html_nodes</span>(webpage, <span class="st">&quot;.petition-overview-info-title&quot;</span>)</span>
<span id="cb57-2"><a href="introduction-to-web-scraping-in-r.html#cb57-2" tabindex="-1"></a>title</span></code></pre></div>
<p>This already looks more structured: it is a list of all the parts in the code that where tagged as <code>.petition-overview-info-title</code>. In the next step, we parse (clean up) this list further to keep only the clean text:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="introduction-to-web-scraping-in-r.html#cb58-1" tabindex="-1"></a>title <span class="ot">&lt;-</span> <span class="fu">html_text</span>(title)</span>
<span id="cb58-2"><a href="introduction-to-web-scraping-in-r.html#cb58-2" tabindex="-1"></a>title</span></code></pre></div>
<p>This basically constitutes our variable “title” for our intended data frame, filled with the values of the petitions on this page.</p>
<p><strong>Question:</strong> how many titles do we have now? And is this the number you would expect?</p>
<p>We can now do the same for our next variable, the url. Using our scrapemate tool again (we can either reset our earlier picker by clicking the circle button next to it, or use one of the other pickers in the sidebar), we can determine that the CSS tag in this case is <code>.petition-overview-image-container</code>.</p>
<p>The code to get all the URLs then looks like this:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="introduction-to-web-scraping-in-r.html#cb59-1" tabindex="-1"></a>link_url <span class="ot">&lt;-</span> <span class="fu">html_elements</span>(webpage, <span class="st">&quot;.petition-overview-image-container&quot;</span>)</span>
<span id="cb59-2"><a href="introduction-to-web-scraping-in-r.html#cb59-2" tabindex="-1"></a>link_url <span class="ot">&lt;-</span> <span class="fu">html_attr</span>(link_url, <span class="st">&quot;href&quot;</span>)</span></code></pre></div>
<p><strong>Exercise:</strong> now write the code to get the number of signatures per petition.</p>
</div>
<div id="automating-the-process-getting-multiple-pages" class="section level3 hasAnchor" number="2.6.2">
<h3><span class="header-section-number">2.6.2</span> Automating the process: getting multiple pages<a href="introduction-to-web-scraping-in-r.html#automating-the-process-getting-multiple-pages" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>At this point, we can scrape the required information from the one page, namely, <a href="https://petities.nl/petitions/all?locale=en">https://petities.nl/petitions/all</a>. However, for our research project, we’re probably interested in more than just these 12 petitions; we want to get a sizable sample of petitions and perhaps even all petitions listed on the website. At the bottom of the page, we see that the list of petitions continues on page 2, 3, etc.</p>
<p><strong>Question:</strong> how many pages does the list of petitions contain in total?</p>
<p>Now of course we could just manually go to the next page, check the url for that page, and repeat our earlier scraping steps to get the petitions for that page.</p>
<p><strong>Question:</strong> what is the URL of page 2? And page 3?</p>
<p>However, this would be very tedious and take a long time. Rather, we’d like to <em>automate</em> this process so that our scraper automatically visits all the pages, and downloads the data. With that, we’re getting to the “crawling” part of web scraping, and it will require a little <em>programming</em>. While this may sound intimidating, it simply means that we are going to “recycle” our earlier instructions to the computer in a smart way. We’ve so far written our code for a <em>specific</em> URL; let’s now write in a way that can be applied to <em>any</em> URL. To do so, we include our earlier code in a <em>function</em> called get_petitions_list():</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="introduction-to-web-scraping-in-r.html#cb60-1" tabindex="-1"></a>get_petitions_list <span class="ot">&lt;-</span> <span class="cf">function</span>(page_url){</span>
<span id="cb60-2"><a href="introduction-to-web-scraping-in-r.html#cb60-2" tabindex="-1"></a>  webpage <span class="ot">&lt;-</span> <span class="fu">read_html</span>(page_url) </span>
<span id="cb60-3"><a href="introduction-to-web-scraping-in-r.html#cb60-3" tabindex="-1"></a>  </span>
<span id="cb60-4"><a href="introduction-to-web-scraping-in-r.html#cb60-4" tabindex="-1"></a>  title <span class="ot">&lt;-</span> <span class="fu">html_nodes</span>(webpage, <span class="st">&quot;.petition-overview-info-title&quot;</span>)</span>
<span id="cb60-5"><a href="introduction-to-web-scraping-in-r.html#cb60-5" tabindex="-1"></a>  title <span class="ot">&lt;-</span> <span class="fu">html_text</span>(title)</span>
<span id="cb60-6"><a href="introduction-to-web-scraping-in-r.html#cb60-6" tabindex="-1"></a></span>
<span id="cb60-7"><a href="introduction-to-web-scraping-in-r.html#cb60-7" tabindex="-1"></a>  </span>
<span id="cb60-8"><a href="introduction-to-web-scraping-in-r.html#cb60-8" tabindex="-1"></a>  link_url <span class="ot">&lt;-</span> <span class="fu">html_elements</span>(webpage, <span class="st">&quot;.petition-overview-image-container&quot;</span>)</span>
<span id="cb60-9"><a href="introduction-to-web-scraping-in-r.html#cb60-9" tabindex="-1"></a>  link_url <span class="ot">&lt;-</span> <span class="fu">html_attr</span>(link_url, <span class="st">&quot;href&quot;</span>)</span>
<span id="cb60-10"><a href="introduction-to-web-scraping-in-r.html#cb60-10" tabindex="-1"></a>  </span>
<span id="cb60-11"><a href="introduction-to-web-scraping-in-r.html#cb60-11" tabindex="-1"></a>  </span>
<span id="cb60-12"><a href="introduction-to-web-scraping-in-r.html#cb60-12" tabindex="-1"></a>  sig_count <span class="ot">&lt;-</span> <span class="fu">html_elements</span>(webpage, <span class="st">&quot;.petitions-counter&quot;</span>)</span>
<span id="cb60-13"><a href="introduction-to-web-scraping-in-r.html#cb60-13" tabindex="-1"></a>  sig_count <span class="ot">&lt;-</span> <span class="fu">html_text</span>(sig_count) </span>
<span id="cb60-14"><a href="introduction-to-web-scraping-in-r.html#cb60-14" tabindex="-1"></a>  </span>
<span id="cb60-15"><a href="introduction-to-web-scraping-in-r.html#cb60-15" tabindex="-1"></a>  </span>
<span id="cb60-16"><a href="introduction-to-web-scraping-in-r.html#cb60-16" tabindex="-1"></a>  petitions_list <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(title, link_url, sig_count)</span>
<span id="cb60-17"><a href="introduction-to-web-scraping-in-r.html#cb60-17" tabindex="-1"></a>  <span class="fu">return</span>(petitions_list)</span>
<span id="cb60-18"><a href="introduction-to-web-scraping-in-r.html#cb60-18" tabindex="-1"></a>}</span></code></pre></div>
<p>If we run this code, nothing really happens yet: all it does is <em>define</em> the function. That is, we can now refer to this set of scraping instructions using the function <code>get_petitions_list()</code>, filling in the URL of the page that we want to scrape as “page_url”. All the code inside the function will then be applied to this page. Specifically, it does the following:</p>
<ol style="list-style-type: decimal">
<li><p>Download the source code of the page</p></li>
<li><p>Extract the titles of the petitions</p></li>
<li><p>Extract the link urls for each petition</p></li>
<li><p>Extract the signature counts for each petition</p></li>
<li><p>Combine the results in a single data frame</p></li>
</ol>
<p>The last line in the function starting with <code>return</code> defines the result of the function, in this case, the data frame.</p>
<p>Let’s test this function on page 2:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="introduction-to-web-scraping-in-r.html#cb61-1" tabindex="-1"></a>p2_petitions <span class="ot">&lt;-</span> <span class="fu">get_petitions_list</span>(<span class="st">&quot;https://petities.nl/petitions/all?locale=en&amp;page=2&quot;</span>)</span></code></pre></div>
<p><strong>Question</strong>: did it work correctly?</p>
<p>Now that we have a function to get all the data that we want from a given page in one go, all we need to to is apply this to all the pages we want to scrape and combine the results into a single data frame. To do so, we’ll use a <em>loop:</em></p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="introduction-to-web-scraping-in-r.html#cb62-1" tabindex="-1"></a>petitions <span class="ot">&lt;-</span> <span class="fu">get_petitions_list</span>(<span class="st">&quot;https://petities.nl/petitions/all?locale=en&amp;page=1&quot;</span>) <span class="co"># We start with the first page</span></span>
<span id="cb62-2"><a href="introduction-to-web-scraping-in-r.html#cb62-2" tabindex="-1"></a></span>
<span id="cb62-3"><a href="introduction-to-web-scraping-in-r.html#cb62-3" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>){ <span class="co"># Loop throup all values from 2 to 5. The current value is &quot;i&quot; </span></span>
<span id="cb62-4"><a href="introduction-to-web-scraping-in-r.html#cb62-4" tabindex="-1"></a>  target_page <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">&quot;https://petities.nl/petitions/all?locale=en&amp;page=&quot;</span>,i,<span class="at">sep =</span> <span class="st">&quot;&quot;</span>) <span class="co"># Create a string in with we add the current value i to the &quot;stub&quot; of the page url</span></span>
<span id="cb62-5"><a href="introduction-to-web-scraping-in-r.html#cb62-5" tabindex="-1"></a>  p <span class="ot">&lt;-</span><span class="fu">get_petitions_list</span>(target_page) <span class="co"># scrape page i</span></span>
<span id="cb62-6"><a href="introduction-to-web-scraping-in-r.html#cb62-6" tabindex="-1"></a>  petitions <span class="ot">&lt;-</span> <span class="fu">rbind</span>(petitions, p) <span class="co"># add the petitions of page i to what we already had </span></span>
<span id="cb62-7"><a href="introduction-to-web-scraping-in-r.html#cb62-7" tabindex="-1"></a>}</span></code></pre></div>
<p>See if you understand the above code with the help of the comments in the code. If you don’t know the additional functions that we use in the loop (for example, paste() or rbind() ), look them up to see what they do. Then, run the code.</p>
<p><strong>Question:</strong> What do you expect as the result, and is it correct?</p>
<p><strong>Question:</strong> what would we need to change in the above code to collect data on <em>all</em> petitions on the website?</p>
<p><u><strong>NOTE:</strong></u> at this point, do not actually run the code to collect data for all petitions. While this is tempting, it would 1) take a long time and 2) put an unnecessarily large burden on the Petities.nl servers.</p>
<p>In principle, we now have a completely functional scraper! It is capable of automatically visiting a number of pages that we define, and collect the information from those pages that we wanted. Let’s just implement a few small improvements.</p>
<p>First, you might have notices that the number of signatures is included in the data frame as a string variable, while it is actually a number. To avoid that we have to fix this afterwords, we can already fix it in our function (see “# NEW”):</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="introduction-to-web-scraping-in-r.html#cb63-1" tabindex="-1"></a>get_petitions_list <span class="ot">&lt;-</span> <span class="cf">function</span>(page_url){</span>
<span id="cb63-2"><a href="introduction-to-web-scraping-in-r.html#cb63-2" tabindex="-1"></a>  webpage <span class="ot">&lt;-</span> <span class="fu">read_html</span>(page_url) </span>
<span id="cb63-3"><a href="introduction-to-web-scraping-in-r.html#cb63-3" tabindex="-1"></a>  </span>
<span id="cb63-4"><a href="introduction-to-web-scraping-in-r.html#cb63-4" tabindex="-1"></a>  title <span class="ot">&lt;-</span> <span class="fu">html_nodes</span>(webpage, <span class="st">&quot;.petition-overview-info-title&quot;</span>)</span>
<span id="cb63-5"><a href="introduction-to-web-scraping-in-r.html#cb63-5" tabindex="-1"></a>  title <span class="ot">&lt;-</span> <span class="fu">html_text</span>(title)</span>
<span id="cb63-6"><a href="introduction-to-web-scraping-in-r.html#cb63-6" tabindex="-1"></a></span>
<span id="cb63-7"><a href="introduction-to-web-scraping-in-r.html#cb63-7" tabindex="-1"></a>  </span>
<span id="cb63-8"><a href="introduction-to-web-scraping-in-r.html#cb63-8" tabindex="-1"></a>  link_url <span class="ot">&lt;-</span> <span class="fu">html_elements</span>(webpage, <span class="st">&quot;.petition-overview-image-container&quot;</span>)</span>
<span id="cb63-9"><a href="introduction-to-web-scraping-in-r.html#cb63-9" tabindex="-1"></a>  link_url <span class="ot">&lt;-</span> <span class="fu">html_attr</span>(link_url, <span class="st">&quot;href&quot;</span>)</span>
<span id="cb63-10"><a href="introduction-to-web-scraping-in-r.html#cb63-10" tabindex="-1"></a>  </span>
<span id="cb63-11"><a href="introduction-to-web-scraping-in-r.html#cb63-11" tabindex="-1"></a>  </span>
<span id="cb63-12"><a href="introduction-to-web-scraping-in-r.html#cb63-12" tabindex="-1"></a>  sig_count <span class="ot">&lt;-</span> <span class="fu">html_elements</span>(webpage, <span class="st">&quot;.petitions-counter&quot;</span>)</span>
<span id="cb63-13"><a href="introduction-to-web-scraping-in-r.html#cb63-13" tabindex="-1"></a>  sig_count <span class="ot">&lt;-</span> <span class="fu">html_text</span>(sig_count)</span>
<span id="cb63-14"><a href="introduction-to-web-scraping-in-r.html#cb63-14" tabindex="-1"></a>  sig_count <span class="ot">&lt;-</span> <span class="fu">str_replace_all</span>(sig_count, <span class="st">&quot;</span><span class="sc">\\</span><span class="st">.&quot;</span>,<span class="st">&quot;&quot;</span>) <span class="co"># NEW: remove Dutch 1000 separator</span></span>
<span id="cb63-15"><a href="introduction-to-web-scraping-in-r.html#cb63-15" tabindex="-1"></a>  sig_count <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(sig_count) <span class="co"># NEW: change the type from string to numeric</span></span>
<span id="cb63-16"><a href="introduction-to-web-scraping-in-r.html#cb63-16" tabindex="-1"></a>  </span>
<span id="cb63-17"><a href="introduction-to-web-scraping-in-r.html#cb63-17" tabindex="-1"></a>  petitions_list <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(title, link_url, sig_count)</span>
<span id="cb63-18"><a href="introduction-to-web-scraping-in-r.html#cb63-18" tabindex="-1"></a>  <span class="fu">return</span>(petitions_list)</span>
<span id="cb63-19"><a href="introduction-to-web-scraping-in-r.html#cb63-19" tabindex="-1"></a>}</span></code></pre></div>
<p>Second, you may have noticed that scraping five pages (probably) already took a noticeable amount of time. If we’d want to scrape many more pages, we may want to be able to keep track of the progress. For that purpose, we let R print some text to the console to report what going on, in our loop:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="introduction-to-web-scraping-in-r.html#cb64-1" tabindex="-1"></a>petitions <span class="ot">&lt;-</span> <span class="fu">get_petitions_list</span>(<span class="st">&quot;https://petities.nl/petitions/all?locale=en&amp;page=1&quot;</span>) <span class="co"># We start with the first page</span></span>
<span id="cb64-2"><a href="introduction-to-web-scraping-in-r.html#cb64-2" tabindex="-1"></a></span>
<span id="cb64-3"><a href="introduction-to-web-scraping-in-r.html#cb64-3" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>){ <span class="co"># Loop throup all values from 2 to 5. The current value is &quot;i&quot; </span></span>
<span id="cb64-4"><a href="introduction-to-web-scraping-in-r.html#cb64-4" tabindex="-1"></a>    <span class="fu">message</span>(<span class="fu">paste</span>(<span class="st">&quot;scraping page&quot;</span>,i,<span class="at">sep=</span>)) <span class="co">#NEW: print what&#39;s happening to the console</span></span>
<span id="cb64-5"><a href="introduction-to-web-scraping-in-r.html#cb64-5" tabindex="-1"></a></span>
<span id="cb64-6"><a href="introduction-to-web-scraping-in-r.html#cb64-6" tabindex="-1"></a>  target_page <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">&quot;https://petities.nl/petitions/all?locale=en&amp;page=&quot;</span>,i,<span class="at">sep =</span> <span class="st">&quot;&quot;</span>) <span class="co"># Create a string in with we add the current value i to the &quot;stub&quot; of the page url</span></span>
<span id="cb64-7"><a href="introduction-to-web-scraping-in-r.html#cb64-7" tabindex="-1"></a>  p <span class="ot">&lt;-</span><span class="fu">get_petitions_list</span>(target_page) <span class="co"># scrape page i</span></span>
<span id="cb64-8"><a href="introduction-to-web-scraping-in-r.html#cb64-8" tabindex="-1"></a>  petitions <span class="ot">&lt;-</span> <span class="fu">rbind</span>(petitions, p) <span class="co"># add the petitions of page i to what we already had </span></span>
<span id="cb64-9"><a href="introduction-to-web-scraping-in-r.html#cb64-9" tabindex="-1"></a>}</span></code></pre></div>
<p>You may find that you every now and then get a warning “NAs introduced by coercion” (and if not now, you will certainly later). “NA” is R’s term for missing values. If we look at the data (click “petitions” in the environment tab in the top right), we indeed see that some petitions get the value “NA” (that is, missing) for sig_count.</p>
<p><strong>Question:</strong> What is the issue with these specific petitions (hint: look them up on the website)? And to what extent is this really a problem?</p>
</div>
</div>
<div id="answering-the-research-question" class="section level2 hasAnchor" number="2.7">
<h2><span class="header-section-number">2.7</span> Answering the research question<a href="introduction-to-web-scraping-in-r.html#answering-the-research-question" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="collecting-the-data" class="section level3 hasAnchor" number="2.7.1">
<h3><span class="header-section-number">2.7.1</span> Collecting the data<a href="introduction-to-web-scraping-in-r.html#collecting-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now that we have our scraper ready, we can start to use it to answer our descriptive research question (see above).First we need to collect a larger amount of data. In a real research project, you would probably want to collect the data of <em>all</em> the petitions on the website. However, since this is an educational project, we don’t want to put too much unnecessary strain on the server, and we have many students accessing the server at the same time, let’s limit our data collection to 25 pages.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="introduction-to-web-scraping-in-r.html#cb65-1" tabindex="-1"></a>petitions <span class="ot">&lt;-</span> <span class="fu">get_petitions_list</span>(<span class="st">&quot;https://petities.nl/petitions/all?locale=en&amp;page=1&quot;</span>) <span class="co"># We start with the first page</span></span>
<span id="cb65-2"><a href="introduction-to-web-scraping-in-r.html#cb65-2" tabindex="-1"></a></span>
<span id="cb65-3"><a href="introduction-to-web-scraping-in-r.html#cb65-3" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">25</span>){ <span class="co"># Loop throup all values from 2 to 5. The current value is &quot;i&quot; </span></span>
<span id="cb65-4"><a href="introduction-to-web-scraping-in-r.html#cb65-4" tabindex="-1"></a>    <span class="fu">message</span>(<span class="fu">paste</span>(<span class="st">&quot;scraping page&quot;</span>,i,<span class="at">sep=</span>)) <span class="co">#NEW: print what&#39;s happening to the console</span></span>
<span id="cb65-5"><a href="introduction-to-web-scraping-in-r.html#cb65-5" tabindex="-1"></a></span>
<span id="cb65-6"><a href="introduction-to-web-scraping-in-r.html#cb65-6" tabindex="-1"></a>  target_page <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">&quot;https://petities.nl/petitions/all?locale=en&amp;page=&quot;</span>,i,<span class="at">sep =</span> <span class="st">&quot;&quot;</span>) <span class="co"># Create a string in with we add the current value i to the &quot;stub&quot; of the page url</span></span>
<span id="cb65-7"><a href="introduction-to-web-scraping-in-r.html#cb65-7" tabindex="-1"></a>  p <span class="ot">&lt;-</span><span class="fu">get_petitions_list</span>(target_page) <span class="co"># scrape page i</span></span>
<span id="cb65-8"><a href="introduction-to-web-scraping-in-r.html#cb65-8" tabindex="-1"></a>  petitions <span class="ot">&lt;-</span> <span class="fu">rbind</span>(petitions, p) <span class="co"># add the petitions of page i to what we already had </span></span>
<span id="cb65-9"><a href="introduction-to-web-scraping-in-r.html#cb65-9" tabindex="-1"></a>}</span></code></pre></div>
<p><strong>Question:</strong> Of how many petitions have you now collected data?</p>
</div>
<div id="analyzing-the-data" class="section level3 hasAnchor" number="2.7.2">
<h3><span class="header-section-number">2.7.2</span> Analyzing the data<a href="introduction-to-web-scraping-in-r.html#analyzing-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Next, let’s analyze these data a bit. First, let’s get rid of these annoying “NA” values and replace them by 0. The “coalesce()” function helps with that:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="introduction-to-web-scraping-in-r.html#cb66-1" tabindex="-1"></a>petitions<span class="sc">$</span>sig_count <span class="ot">&lt;-</span> <span class="fu">coalesce</span>(petitions<span class="sc">$</span>sig_count, <span class="dv">0</span>) <span class="co"># replace missings by 0</span></span></code></pre></div>
<p>For a first look at the data, we can draw a simple histogram:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="introduction-to-web-scraping-in-r.html#cb67-1" tabindex="-1"></a><span class="fu">hist</span>(petitions<span class="sc">$</span>sig_count)</span></code></pre></div>
<p><strong>Question:</strong> What is your first conclusion about the distribution of success?</p>
<p>In their analysis of the data, Margetts et al. visualize the data somewhat differently, in a way that helps to assess the skewness of the distribution a bit better. In particular, they plot the number of signatures against the <em>rank</em> of each petition in terms of signatures, and furthermore, they use logarithmic axes. To recreate their plot, we can do the following:</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="introduction-to-web-scraping-in-r.html#cb68-1" tabindex="-1"></a><span class="co"># First we create a rank variable (more signatures = higher rank)</span></span>
<span id="cb68-2"><a href="introduction-to-web-scraping-in-r.html#cb68-2" tabindex="-1"></a>petitions <span class="ot">&lt;-</span>  <span class="fu">mutate</span>(petitions, <span class="at">rank =</span> <span class="fu">dense_rank</span>(<span class="fu">desc</span>(sig_count)))</span>
<span id="cb68-3"><a href="introduction-to-web-scraping-in-r.html#cb68-3" tabindex="-1"></a></span>
<span id="cb68-4"><a href="introduction-to-web-scraping-in-r.html#cb68-4" tabindex="-1"></a><span class="co"># To avoid that petitions with zero signatures are left out of the plot (because the logarithm of zero is not defined) we add 1 to all values:</span></span>
<span id="cb68-5"><a href="introduction-to-web-scraping-in-r.html#cb68-5" tabindex="-1"></a></span>
<span id="cb68-6"><a href="introduction-to-web-scraping-in-r.html#cb68-6" tabindex="-1"></a>petitions<span class="sc">$</span>sig_count <span class="ot">&lt;-</span> petitions<span class="sc">$</span>sig_count <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb68-7"><a href="introduction-to-web-scraping-in-r.html#cb68-7" tabindex="-1"></a></span>
<span id="cb68-8"><a href="introduction-to-web-scraping-in-r.html#cb68-8" tabindex="-1"></a></span>
<span id="cb68-9"><a href="introduction-to-web-scraping-in-r.html#cb68-9" tabindex="-1"></a><span class="co"># Finally, we plot the data:</span></span>
<span id="cb68-10"><a href="introduction-to-web-scraping-in-r.html#cb68-10" tabindex="-1"></a><span class="fu">plot</span>(petitions<span class="sc">$</span>rank, petitions<span class="sc">$</span>sig_count, <span class="at">log =</span> <span class="st">&quot;xy&quot;</span>)</span></code></pre></div>
<p><strong>Question:</strong>: Compare your figure to Figure 3.4 in the Chapter by Margetts et al. Does the distribution of success in the Netherlands look more like the one in the UK or the one in the US?</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="a-very-short-introduction-to-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="collecting-data-through-apis-the-case-of-reddit.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
