<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Accessing data via the API | Social Research in the Digital Age (Utrecht University)</title>
  <meta name="description" content="4 Accessing data via the API | Social Research in the Digital Age (Utrecht University)" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Accessing data via the API | Social Research in the Digital Age (Utrecht University)" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Accessing data via the API | Social Research in the Digital Age (Utrecht University)" />
  
  
  

<meta name="author" content="Rense Corten" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="collecting-data-through-apis-the-case-of-reddit.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#usage"><i class="fa fa-check"></i>Usage</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="a-very-short-introduction-to-r.html"><a href="a-very-short-introduction-to-r.html"><i class="fa fa-check"></i><b>1</b> A Very Short Introduction to R</a></li>
<li class="chapter" data-level="2" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html"><i class="fa fa-check"></i><b>2</b> Introduction to web scraping in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#some-preliminaries-about-websites-scraping-and-crawling"><i class="fa fa-check"></i><b>2.1</b> Some preliminaries: about websites, scraping, and crawling</a></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#getting-our-tools-ready"><i class="fa fa-check"></i><b>2.2</b> Getting our tools ready</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#getting-to-know-the-target-website"><i class="fa fa-check"></i><b>2.3</b> Getting to know the target website</a></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#making-a-plan"><i class="fa fa-check"></i><b>2.4</b> Making a plan</a></li>
<li class="chapter" data-level="2.5" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#locating-the-correct-information"><i class="fa fa-check"></i><b>2.5</b> Locating the correct information</a></li>
<li class="chapter" data-level="2.6" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#building-the-scraper"><i class="fa fa-check"></i><b>2.6</b> Building the scraper</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#first-steps"><i class="fa fa-check"></i><b>2.6.1</b> First steps</a></li>
<li class="chapter" data-level="2.6.2" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#automating-the-process-getting-multiple-pages"><i class="fa fa-check"></i><b>2.6.2</b> Automating the process: getting multiple pages</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#answering-the-research-question"><i class="fa fa-check"></i><b>2.7</b> Answering the research question</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#collecting-the-data"><i class="fa fa-check"></i><b>2.7.1</b> Collecting the data</a></li>
<li class="chapter" data-level="2.7.2" data-path="introduction-to-web-scraping-in-r.html"><a href="introduction-to-web-scraping-in-r.html#analyzing-the-data"><i class="fa fa-check"></i><b>2.7.2</b> Analyzing the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="collecting-data-through-apis-the-case-of-reddit.html"><a href="collecting-data-through-apis-the-case-of-reddit.html"><i class="fa fa-check"></i><b>3</b> Collecting data through APIs: the case of Reddit</a>
<ul>
<li class="chapter" data-level="3.1" data-path="collecting-data-through-apis-the-case-of-reddit.html"><a href="collecting-data-through-apis-the-case-of-reddit.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="collecting-data-through-apis-the-case-of-reddit.html"><a href="collecting-data-through-apis-the-case-of-reddit.html#loading-the-tools"><i class="fa fa-check"></i><b>3.2</b> Loading the tools</a></li>
<li class="chapter" data-level="3.3" data-path="collecting-data-through-apis-the-case-of-reddit.html"><a href="collecting-data-through-apis-the-case-of-reddit.html#case-study-reddit"><i class="fa fa-check"></i><b>3.3</b> Case study: Reddit</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="accessing-data-via-the-api.html"><a href="accessing-data-via-the-api.html"><i class="fa fa-check"></i><b>4</b> Accessing data via the API</a>
<ul>
<li class="chapter" data-level="4.1" data-path="accessing-data-via-the-api.html"><a href="accessing-data-via-the-api.html#getting-the-data-with-redditextractor"><i class="fa fa-check"></i><b>4.1</b> Getting the data with RedditExtractoR</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="accessing-data-via-the-api.html"><a href="accessing-data-via-the-api.html#getting-threads"><i class="fa fa-check"></i><b>4.1.1</b> Getting threads</a></li>
<li class="chapter" data-level="4.1.2" data-path="accessing-data-via-the-api.html"><a href="accessing-data-via-the-api.html#getting-contents-of-threads"><i class="fa fa-check"></i><b>4.1.2</b> Getting contents of threads</a></li>
<li class="chapter" data-level="4.1.3" data-path="accessing-data-via-the-api.html"><a href="accessing-data-via-the-api.html#creating-a-network"><i class="fa fa-check"></i><b>4.1.3</b> Creating a network</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Social Research in the Digital Age (Utrecht University)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="accessing-data-via-the-api" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">4</span> Accessing data via the API<a href="accessing-data-via-the-api.html#accessing-data-via-the-api" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>To get data from the API, we can use specific URLs that provide us with the data we want. Instead of a readable webpages, these URLs provide data based on what we specify. For example, to download a list of threads, we could specify the following:</p>
<pre><code>https://www.reddit.com/r/{subreddit}/{listing}.json?limit={count}&amp;t={timeframe}</code></pre>
<p>Where:</p>
<dl>
<dt>{subreddit}</dt>
<dd>
<p>The name of the subreddit we want to access;</p>
</dd>
<dt>{listing}</dt>
<dd>
<p>Determines the order of the list: “controversial”, “best”, “hot”, “new”, “random”, “rising”, or “top”;</p>
</dd>
<dt>{limit}</dt>
<dd>
<p>The number of desired results;</p>
</dd>
<dt>{timeframe}</dt>
<dd>
<p>The time frame to which {listing} applies: “hour”, “day”, “week”, “month”, “year”, “all” (i.e., the top posts of the past month).</p>
</dd>
</dl>
<p>In other words, the URL above says “please give me {limit} {listing} threads from the past {timeframe} from subreddit {subreddit}.</p>
<p><strong>Question:</strong> consider <a href="https://www.reddit.com/r/climate/new.json?limit=1&amp;t=all" class="uri">https://www.reddit.com/r/climate/new.json?limit=1&amp;t=all</a>. What are we requesting here (i.e., what are {subreddit}, {listing}, {limit} and {timeframe}?</p>
<p><strong>Question:</strong> Now go to <a href="https://www.reddit.com/r/climate" class="uri">https://www.reddit.com/r/climate</a>. Which information here corresponds with what we requested in the previous question?</p>
<p>Now click on <a href="https://www.reddit.com/r/climate/new.json?limit=1&amp;t=all" class="uri">https://www.reddit.com/r/climate/new.json?limit=1&amp;t=all</a>. What you see here is indeed not a nicely formatted website, but a whole lot of data. The data are structured using the <a href="https://en.wikipedia.org/wiki/JSON">JSON</a> format, which is a common format for exchanging data online. This is a key difference between using an API and typical web scraping: in the latter case, the data are somwhere on a website that is designed to be human-readable, and we have to somehow filter out the relevant information; via the API data are already provided in a nicely structured way, and are <em>intended to be used</em>.</p>
<p><strong>Question:</strong> Identify the the following information in the JSON file you see in your browser: the title of the post, the name of its author, the current number of comments, and the date/time of posting.</p>
<p>We could easily download the JSON data into R using a simple command like this (copy and paste into your R script and run it; ignore the warning):</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="accessing-data-via-the-api.html#cb64-1" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">readLines</span>(<span class="st">&quot;https://www.reddit.com/r/climate/new.json?limit=1&amp;t=all&quot;</span>)</span></code></pre></div>
<p>Subsequently we can run</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="accessing-data-via-the-api.html#cb65-1" tabindex="-1"></a>x</span></code></pre></div>
<p>to view the data (try it), but the result is still quite messy. We could parse the data using R’s built-in JSON tools, but fortunately there is also an R-package specifically for Reddit that makes getting data from the Reddit API into R much more user-friendly. It’s called RedditExtractoR and we’ve already loaded it above.</p>
<div id="getting-the-data-with-redditextractor" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Getting the data with RedditExtractoR<a href="accessing-data-via-the-api.html#getting-the-data-with-redditextractor" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="getting-threads" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Getting threads<a href="accessing-data-via-the-api.html#getting-threads" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As a first step, we download all the threads in the Subreddit. All? Not all. It seems actually unclear how many one can download. Choosing “new” and “all” seems to give a relatively large (and sensible) result.</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="accessing-data-via-the-api.html#cb66-1" tabindex="-1"></a>threads <span class="ot">&lt;-</span> <span class="fu">find_thread_urls</span>(<span class="at">subreddit=</span><span class="st">&quot;climate&quot;</span>, <span class="at">sort_by=</span><span class="st">&quot;new&quot;</span>, <span class="at">period =</span> <span class="st">&quot;all&quot;</span>)</span></code></pre></div>
<p>Take a look at the resulting data frame (click on “threads” in the environment tab in the top right corner.</p>
<p><strong>Question:</strong> How many threads have we downloaded? Which variables are available about each thread? Which thread is the thread that received most comments in these data?</p>
<p><strong>Question:</strong> Make a histogram of the number of comments. (Hint: look up the code for the histogram that we made in the previous tutorial.)</p>
</div>
<div id="getting-contents-of-threads" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Getting contents of threads<a href="accessing-data-via-the-api.html#getting-contents-of-threads" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the next step, we download the contents of these threads. Let’s take only a randomly chosen 50 for simplicity. Note that it is normal that the below code takes a bit of time to run.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="accessing-data-via-the-api.html#cb67-1" tabindex="-1"></a>thread_contents <span class="ot">&lt;-</span> threads<span class="sc">$</span>url  <span class="co"># start with the urls from the threads data frame</span></span>
<span id="cb67-2"><a href="accessing-data-via-the-api.html#cb67-2" tabindex="-1"></a>thread_contents <span class="ot">&lt;-</span>  <span class="fu">sample</span>(thread_contents, <span class="dv">50</span>) <span class="co"># randomly sample 50</span></span>
<span id="cb67-3"><a href="accessing-data-via-the-api.html#cb67-3" tabindex="-1"></a>thread_contents <span class="ot">&lt;-</span>  <span class="fu">get_thread_content</span>(thread_contents)</span></code></pre></div>
<p>The resulting object contains two data frames: “threads” and “comments”. The first contains data on the thread as a whole (such as the url, who started it and when, the number of comments, the content of the original post, etc. ). The second contains data of all the comments. Some important variables in “comments” are:</p>
<dl>
<dt>url</dt>
<dd>
<p>the url of the thread that the comment belongs to. This matches the urls in the “threads” data frame in “thread_contents”.</p>
</dd>
<dt>author</dt>
<dd>
<p>The author of the comment</p>
</dd>
<dt>comment_id</dt>
<dd>
<p>The position of the comment in the “tree” of the thread. “1” is the first comment to the original post, “2” is the second, etc. “1_1” is then the first comment to the first comment to the original post, etc.</p>
</dd>
</dl>
<p>We can take the data frame with comments from the <code>threads_contents</code> object and turn it into its own data frame as follows:</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="accessing-data-via-the-api.html#cb68-1" tabindex="-1"></a>comments <span class="ot">&lt;-</span> thread_contents<span class="sc">$</span>comments</span></code></pre></div>
<p><strong>Question:</strong> How many comments are there in total?</p>
<p><strong>Question:</strong> Which comment is the most “upvoted” comment?</p>
<p><strong>Question:</strong> The paper by <a href="https://www.tandfonline.com/doi/full/10.1080/17524032.2022.2050776">Treen et al. (2022)</a> used text analysis techniques such as <em>topic modeling</em> in their analysis of polarization on Reddit. Of the data that we have now collected, what do you think they used?</p>
</div>
<div id="creating-a-network" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Creating a network<a href="accessing-data-via-the-api.html#creating-a-network" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The paper by <a href="https://www.tandfonline.com/doi/full/10.1080/17524032.2022.2050776">Treen et al. (2022)</a> aims to assess polarization by, among other things, studying the “reply network” in Subreddits.</p>
<p><strong>Question:</strong> how do they construct this network, that is, what are the links? And how do they assess the level of polarization?</p>
<p>We can partly reproduce their analysis (for “our” Subreddit) using the code below. While this is relatively complicated, see of you can get the gist of what happens. Then, copy-paste and run the code.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="accessing-data-via-the-api.html#cb69-1" tabindex="-1"></a>authors <span class="ot">&lt;-</span> thread_contents<span class="sc">$</span>threads <span class="sc">%&gt;%</span> <span class="co"># Get the &quot;threads&quot; part of the threat_contents object </span></span>
<span id="cb69-2"><a href="accessing-data-via-the-api.html#cb69-2" tabindex="-1"></a>  <span class="fu">select</span>(author, url) <span class="co"># keep only the author and url for each thread</span></span>
<span id="cb69-3"><a href="accessing-data-via-the-api.html#cb69-3" tabindex="-1"></a></span>
<span id="cb69-4"><a href="accessing-data-via-the-api.html#cb69-4" tabindex="-1"></a>responders <span class="ot">&lt;-</span> thread_contents<span class="sc">$</span>comments <span class="sc">%&gt;%</span> <span class="co"># Get the &quot;comments&quot; part of the threat_contents object </span></span>
<span id="cb69-5"><a href="accessing-data-via-the-api.html#cb69-5" tabindex="-1"></a>  <span class="fu">select</span>(author, url) <span class="sc">%&gt;%</span> <span class="co"># keep only the author and url for each thread</span></span>
<span id="cb69-6"><a href="accessing-data-via-the-api.html#cb69-6" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="st">&quot;responder&quot;</span> <span class="ot">=</span> author) <span class="co"># rename &quot;author&quot; to &quot;responder&quot;</span></span>
<span id="cb69-7"><a href="accessing-data-via-the-api.html#cb69-7" tabindex="-1"></a></span>
<span id="cb69-8"><a href="accessing-data-via-the-api.html#cb69-8" tabindex="-1"></a><span class="co"># now match these two together, using the url as the matching variable</span></span>
<span id="cb69-9"><a href="accessing-data-via-the-api.html#cb69-9" tabindex="-1"></a>reply_net  <span class="ot">&lt;-</span> <span class="fu">merge</span>(authors, responders, <span class="at">by =</span> <span class="st">&quot;url&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb69-10"><a href="accessing-data-via-the-api.html#cb69-10" tabindex="-1"></a>  <span class="fu">select</span>(author, responder) <span class="sc">%&gt;%</span> <span class="co"># keep only the author and responder vars</span></span>
<span id="cb69-11"><a href="accessing-data-via-the-api.html#cb69-11" tabindex="-1"></a>  <span class="fu">graph_from_data_frame</span>() <span class="co"># turn this into a &quot;network object&quot;: something the igraph package for network analysis can work with</span></span>
<span id="cb69-12"><a href="accessing-data-via-the-api.html#cb69-12" tabindex="-1"></a></span>
<span id="cb69-13"><a href="accessing-data-via-the-api.html#cb69-13" tabindex="-1"></a><span class="co"># plot the network</span></span>
<span id="cb69-14"><a href="accessing-data-via-the-api.html#cb69-14" tabindex="-1"></a><span class="fu">plot</span>(reply_net,</span>
<span id="cb69-15"><a href="accessing-data-via-the-api.html#cb69-15" tabindex="-1"></a>     <span class="at">vertex.label=</span><span class="cn">NA</span>,</span>
<span id="cb69-16"><a href="accessing-data-via-the-api.html#cb69-16" tabindex="-1"></a>     <span class="at">vertex.color =</span> <span class="st">&quot;blue&quot;</span>,</span>
<span id="cb69-17"><a href="accessing-data-via-the-api.html#cb69-17" tabindex="-1"></a>     <span class="at">vertex.size =</span> <span class="dv">5</span>,</span>
<span id="cb69-18"><a href="accessing-data-via-the-api.html#cb69-18" tabindex="-1"></a>     <span class="at">edge.arrow.size =</span> <span class="fl">0.2</span>,</span>
<span id="cb69-19"><a href="accessing-data-via-the-api.html#cb69-19" tabindex="-1"></a>     <span class="at">edge.color =</span> <span class="st">&quot;black&quot;</span>,</span>
<span id="cb69-20"><a href="accessing-data-via-the-api.html#cb69-20" tabindex="-1"></a>     <span class="at">graph.frame =</span> <span class="cn">TRUE</span>,</span>
<span id="cb69-21"><a href="accessing-data-via-the-api.html#cb69-21" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;The reply network of 50 random threads on r/climate&quot;</span></span>
<span id="cb69-22"><a href="accessing-data-via-the-api.html#cb69-22" tabindex="-1"></a>     )</span></code></pre></div>
<p>Note that Treen et al.’s network analysis is somewhat more elaborate; for instance, they use a technique called <a href="https://people.duke.edu/~jmoody77/snh/2021/CommunitiesSNH2021.nb.html">community detection</a> to highlight different subgroups in the network, which we don’t do here for simplicity. Nevertheless, we can still try to assess the polarization of the network loosely by looking at the structure.</p>
<p><strong>Question:</strong> what would you conclude about polarization in this Subreddit?</p>
<p><strong>Question:</strong> Now pick another Subreddit on a topic that you find interesting, and try to make a network graph for this Subreddit as well. (Hint: you can reuse most of the code we’ve used above.)</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="collecting-data-through-apis-the-case-of-reddit.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
